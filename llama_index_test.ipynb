{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4206fa76-d0f2-49a7-a17b-04514426e345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2274123a-66f1-4add-b394-87bba438a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from dataclasses import field as dataclass_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc616e06-51df-4196-a839-17539d839e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jmespath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b91724-79e7-4d69-b24a-bc5789eb3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d5bde8-651e-4cfb-bc83-11c3dc759faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_schema(shema_path):\n",
    "\n",
    "    with open(shema_path, 'r') as file:\n",
    "        try:\n",
    "            data = yaml.safe_load(file)\n",
    "            return data\n",
    "        except yaml.YAMLError as error:\n",
    "            print(f\"error reading YAML file: {error}\")\n",
    "\n",
    "\n",
    "\n",
    "def load_feed():\n",
    "    fpath = \"data/news_feed.json\"\n",
    "    with open(fpath, encoding=\"utf-8\") as f:\n",
    "        data = json.loads(f.read())\n",
    "    bbc_datum = data[\"referenceData\"][\"news\"][\"value\"]\n",
    "    return [x for x in bbc_datum if x.get(\"id\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd9f9a3e-a565-4b4f-bbf7-7fa1a9d9ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class StandardizedItem:\n",
    "    data: Dict[str, Any] = dataclass_field(default_factory=dict)\n",
    "    text_fields: List[Dict[str, Any]] = dataclass_field(default_factory=list) \n",
    "\n",
    "@dataclass\n",
    "class StandardizedResult:\n",
    "    standardized_data: List[StandardizedItem] = dataclass_field(default_factory=list)\n",
    "    metadata_attrs: List[str] = dataclass_field(default_factory=list)\n",
    "    exclude_embedings_attrs: List[str] = dataclass_field(default_factory=list)\n",
    "    exclude_llm_attrs: List[str] = dataclass_field(default_factory=list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6d771e-f183-40b2-85f6-c3b84495e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b16cdfe0-b64f-4fb6-854d-6c3e2bf058c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_exclusion(\n",
    "    metadata_exclude: Dict[str, Any], \n",
    "    source: str\n",
    ") -> tuple:\n",
    "    excluded_llm = metadata_exclude.get(\"llm\", False)\n",
    "    excluded_embed = metadata_exclude.get(\"embed\", False)\n",
    "    excluded_storage = metadata_exclude.get(\"storage\", False)\n",
    "    return (excluded_llm, excluded_embed, excluded_storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785c271b-9dfe-468f-b808-1111a9e73434",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def standardized_data(\n",
    "    raw_datum: List[Dict[str, Any]], \n",
    "    schema: Dict[str, Any], \n",
    "    source: str\n",
    ") -> StandardizedResult:\n",
    "    \"\"\"\n",
    "    Converts a list of raw data dictionaries into a standardized format\n",
    "    according to a schema and source. Also tracks metadata inclusion/exclusion.\n",
    "    \"\"\"\n",
    "    metadata_attrs = set()\n",
    "    exclude_embedings_attrs = set()\n",
    "    exclude_llm_attrs = set()\n",
    "    standardized_data_stream = []\n",
    "    fields = schema.get(\"fields\", [])\n",
    "    for raw_data_item in raw_datum:\n",
    "        standardized_data_point = {}\n",
    "        text_metadata = []\n",
    "        for field in fields:\n",
    "            target_field = field.get(\"field\")\n",
    "            text_field_map = field.get(\"text\", {})\n",
    "            metadata_exclude=field.get(\"metadata_exclude\", {})\n",
    "            \n",
    "            try:\n",
    "                processed_value = raw_data_item[target_field]\n",
    "                standardized_data_point[target_field] = processed_value\n",
    "            except Exception as e:\n",
    "                raise ValueError(f\"Error processing field `{target_field}`\")\n",
    "            \n",
    "            excluded_llm = metadata_exclude.get(\"llm\", False)\n",
    "            excluded_embed = metadata_exclude.get(\"embed\", False)\n",
    "            excluded_storage = metadata_exclude.get(\"storage\", False)\n",
    "                        \n",
    "            if not excluded_storage:\n",
    "                metadata_attrs.add(target_field)\n",
    "            if excluded_embed:\n",
    "                exclude_embedings_attrs.add(target_field)\n",
    "            if excluded_llm:\n",
    "                exclude_llm_attrs.add(target_field)\n",
    "            if text_field_map:\n",
    "                text_metadata.append(\n",
    "                    {\n",
    "                        \"heading\": text_field_map.get(\"heading\"),\n",
    "                        \"value\": processed_value\n",
    "                    }\n",
    "                )\n",
    "        standardized_data_stream.append(\n",
    "                StandardizedItem(\n",
    "                    data=standardized_data_point,\n",
    "                    text_fields=text_metadata\n",
    "                )\n",
    "            )\n",
    "    return StandardizedResult(\n",
    "        standardized_data=standardized_data_stream,\n",
    "        metadata_attrs=list(metadata_attrs),\n",
    "        exclude_embedings_attrs=list(exclude_embedings_attrs),\n",
    "        exclude_llm_attrs=list(exclude_llm_attrs)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3bb9b74-42a9-44c9-bc2f-e538dafcba0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getenv\n",
    "endpoint = getenv(\"OPENSEARCH_ENDPOINT\", \"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "410377b2-bd32-4332-a6e9-7014dd2639b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://localhost:9200'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "524634e9-0d31-4140-a1ae-0c1b709458f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_feed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "163dfc38-beaf-458c-890d-f578a8ad5887",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = load_schema(\"data/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1d07b1-38bd-46e4-abed-029bc14d0993",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = standardized_data(data, schema, \"bbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea9b40c7-472a-4cda-855e-2aa636da8fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _markdown_build(\n",
    "    field_text_configs: List[Dict[str, Any]]\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Constructs a Markdown-formatted string from field text configurations.\n",
    "    Each config should have a 'heading' and 'value'.\n",
    "    \"\"\"\n",
    "    lines = []\n",
    "    for doc_config in field_text_configs:\n",
    "        heading = doc_config.get(\"heading\", \"\")\n",
    "        value = doc_config.get(\"value\", \"\")\n",
    "        if heading:\n",
    "            lines.append(f\"**{heading}**\")\n",
    "        if value:\n",
    "            lines.append(str(value))\n",
    "        lines.append(\"\")\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "def create_document(\n",
    "    doc_id: str, \n",
    "    field_text_configs: List[Dict[str, Any]], \n",
    "    metadata: Dict[str, Any] = None, \n",
    "    exclude_embedings_attrs: List[str] = None, \n",
    "    exclude_llm_attrs: List[str] = None,\n",
    ") -> Document:\n",
    "    \"\"\"\n",
    "    Constructs a Document object with specified field text configurations,\n",
    "    metadata, and excluded keys for embeddings and LLM processing.\n",
    "    \"\"\"\n",
    "    metadata = metadata or {}\n",
    "    exclude_embedings_keys = exclude_embedings_attrs or []\n",
    "    exclude_llm_keys = exclude_llm_attrs or []\n",
    "    doc = Document(\n",
    "        doc_id=doc_id, \n",
    "        excluded_embed_metadata_keys=exclude_embedings_keys, \n",
    "        excluded_llm_metadata_keys=exclude_llm_keys,\n",
    "        text=_markdown_build(field_text_configs))\n",
    "    doc.metadata.update(metadata)\n",
    "    return doc\n",
    "\n",
    "\n",
    "def generate_document_from_standardized_data(source, input, doc_id):\n",
    "    \"\"\"\n",
    "    Generates a list of Document objects from standardized data.\n",
    "\n",
    "    Args:\n",
    "        source: The source identifier used for schema mapping.\n",
    "        data: The raw input data to be standardized.\n",
    "        doc_id: The key used to extract the document ID from each item.\n",
    "\n",
    "    Returns:\n",
    "        A list of Document instances.\n",
    "    \"\"\"\n",
    "    standard_data = standardized_data(data, schema, source)\n",
    "    documents = []\n",
    "    for item in standard_data.standardized_data:\n",
    "        document = create_document(\n",
    "            str(item.data.get(doc_id)),\n",
    "            field_text_configs=item.text_fields,\n",
    "            metadata={\n",
    "                key: value\n",
    "                for key, value in item.data.items()\n",
    "                if key in standard_data.metadata_attrs\n",
    "            },\n",
    "            exclude_embedings_attrs=standard_data.exclude_embedings_attrs,\n",
    "            exclude_llm_attrs=standard_data.exclude_llm_attrs,\n",
    "        )\n",
    "        documents.append(document)\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3f09929-6e02-433c-a684-882faaaa49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"bbc\"\n",
    "input = data\n",
    "doc_id = \"id\"\n",
    "docs = generate_document_from_standardized_data(source, input, doc_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7d0ad2-02d8-493e-a0a9-bbddf35a9b7a",
   "metadata": {},
   "source": [
    "## Ingestion\n",
    "\n",
    "Ingest the news feed using LlamaIndex and OpenAI APIs. For the data ingestion, we use ingestion pipeline. This allows you to customize the chunking, metadata, and embedding of the nodes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320da10c-dafa-4465-a027-68602103a44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from storage_service import StorageService\n",
    "from ingestion_service import IngestionService\n",
    "from ingestion.ingestion_config import transformation_bbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "498319e9-8033-4f49-b62e-3d927b2d364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_config = load_schema(\"data/store_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c6e02ba-aab5-4285-8b8e-db261fecf856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contexts': {'bbc_docs': {'store_configs': {'search_pipeline': 'hybrid-search-pipeline'}}}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1cb933-ae5f-41fc-9846-95b9e9094fed",
   "metadata": {},
   "source": [
    "### Initialize the Storage Service.\n",
    "The storage service initializes a LlamaIndex `OpensearchVectorClient` and a `PostgresDocumentStore` for document management. The role of OpenSearchVectorClient is to integrate a vector search-enabled OpenSearch index into the LlamaIndex vector store framework. It encapsulates the logic for working with OpenSearch (or ElasticSearch) to store and query vector embeddings efficiently.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9fa2db1-f4ac-4119-a908-14727eadfc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "store_service = StorageService(store_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "688c6ed4-a89f-4f5e-be73-a8308d577787",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_serve = IngestionService(store_service, transformation_bbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "095d64bf-a023-4c6f-9480-9f8d38978b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ingest_serve.ingest(docs, batch_size = 2, batch_process=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62845982-4047-436e-a833-6deb101f59e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_docstore = store_service.storage_context_mapping.docstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "73ac13ed-2ef2-4c84-be8c-3f630aebf70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import Settings\n",
    "api_key = Settings.api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0d5dc545-35a0-4748-a797-a47f57b9e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "embed_model = OpenAIEmbedding(\n",
    "                max_retries=50,\n",
    "                embed_batch_size=50,\n",
    "                model=\"text-embedding-ada-002\",\n",
    "                api_key=api_key,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4be95f13-a631-4c41-a961-0ce89547a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    api_key=api_key,\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "404ad9f3-bf8a-4940-a44b-af0083e1bd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "284b0325-2f2a-42b4-8637-a65dab2445f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_index = VectorStoreIndex.from_vector_store(vector_store = store_service.storage_context_mapping.vector_store,\n",
    "                                               embed_model=embed_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e92c98-8afa-4eec-9057-a9239a84943c",
   "metadata": {},
   "source": [
    "## Query the DB using hybrid search retriever\n",
    "\n",
    "Create a structured response using LLMs and pydantic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c4b99f7-8cad-4a41-b58a-ba2225737f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field, BaseModel\n",
    "\n",
    "class FactCheck(BaseModel):\n",
    "    \n",
    "    theme_type: str = Field(description=\"The theme of the retrieved story\")\n",
    "    detail_response: str = Field(description=\"Provide statistics and numbers\")\n",
    "    short_response: str = Field(description=\"Provide important members of the identified story and describe what role the play\")\n",
    "    \n",
    "\n",
    "\n",
    "sllm = llm.as_structured_llm(output_cls=FactCheck)\n",
    "\n",
    "query_engine = bbc_index.as_query_engine(\n",
    "    llm=sllm, similarity_top_k=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94165cc8-d0a1-4c53-ad9b-b3befda4d3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticResponse(response=FactCheck(theme_type='Sports', detail_response=\"Tirunesh Dibaba set a new world record in the women's 5,000m at the Boston Indoor Games, finishing in 14 minutes 32.93 seconds.\", short_response=\"Tirunesh Dibaba won the women's 5,000m event, setting a new world record.\"), source_nodes=[NodeWithScore(node=TextNode(id_='31ff59b2-1784-4ac9-9ef7-cebf6925ce2f', embedding=None, metadata={'id': '0187', 'region': 'EMEA', 'country': 'UK', 'title': 'Dibaba breaks 5,000m world record', 'description': 'Ethiopia\\'s Tirunesh Dibaba set a new world record in winning the women\\'s 5,000m at the Boston Indoor Games.\\n\\nDibaba won in 14 minutes 32.93 seconds to erase the previous world indoor mark of 14:39.29 set by another Ethiopian, Berhane Adera, in Stuttgart last year. But compatriot Kenenisa Bekele\\'s record hopes were dashed when he miscounted his laps in the men\\'s 3,000m and staged his sprint finish a lap too soon. Ireland\\'s Alistair Cragg won in 7:39.89 as Bekele battled to second in 7:41.42. \"I didn\\'t want to sit back and get out-kicked,\" said Cragg. \"So I kept on the pace. The plan was to go with 500m to go no matter what, but when Bekele made the mistake that was it. The race was mine.\" Sweden\\'s Carolina Kluft, the Olympic heptathlon champion, and Slovenia\\'s Jolanda Ceplak had winning performances, too. Kluft took the long jump at 6.63m, while Ceplak easily won the women\\'s 800m in 2:01.52.\\n', 'theme': 'Sport', 'header_path': '/'}, excluded_embed_metadata_keys=['id', 'country', 'theme', 'region'], excluded_llm_metadata_keys=['id', 'country', 'theme', 'region'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='0187', node_type='4', metadata={'id': '0187', 'region': 'EMEA', 'country': 'UK', 'title': 'Dibaba breaks 5,000m world record', 'description': 'Ethiopia\\'s Tirunesh Dibaba set a new world record in winning the women\\'s 5,000m at the Boston Indoor Games.\\n\\nDibaba won in 14 minutes 32.93 seconds to erase the previous world indoor mark of 14:39.29 set by another Ethiopian, Berhane Adera, in Stuttgart last year. But compatriot Kenenisa Bekele\\'s record hopes were dashed when he miscounted his laps in the men\\'s 3,000m and staged his sprint finish a lap too soon. Ireland\\'s Alistair Cragg won in 7:39.89 as Bekele battled to second in 7:41.42. \"I didn\\'t want to sit back and get out-kicked,\" said Cragg. \"So I kept on the pace. The plan was to go with 500m to go no matter what, but when Bekele made the mistake that was it. The race was mine.\" Sweden\\'s Carolina Kluft, the Olympic heptathlon champion, and Slovenia\\'s Jolanda Ceplak had winning performances, too. Kluft took the long jump at 6.63m, while Ceplak easily won the women\\'s 800m in 2:01.52.\\n', 'theme': 'Sport'}, hash='72731b496bb21ce0a3fc6516fd0647d9aa0819ec8ce17b7f74ef7a194bd62426')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='**Title**\\nDibaba breaks 5,000m world record\\n\\n**Description**\\nEthiopia\\'s Tirunesh Dibaba set a new world record in winning the women\\'s 5,000m at the Boston Indoor Games.\\n\\nDibaba won in 14 minutes 32.93 seconds to erase the previous world indoor mark of 14:39.29 set by another Ethiopian, Berhane Adera, in Stuttgart last year. But compatriot Kenenisa Bekele\\'s record hopes were dashed when he miscounted his laps in the men\\'s 3,000m and staged his sprint finish a lap too soon. Ireland\\'s Alistair Cragg won in 7:39.89 as Bekele battled to second in 7:41.42. \"I didn\\'t want to sit back and get out-kicked,\" said Cragg. \"So I kept on the pace. The plan was to go with 500m to go no matter what, but when Bekele made the mistake that was it. The race was mine.\" Sweden\\'s Carolina Kluft, the Olympic heptathlon champion, and Slovenia\\'s Jolanda Ceplak had winning performances, too. Kluft took the long jump at 6.63m, while Ceplak easily won the women\\'s 800m in 2:01.52.', mimetype='text/plain', start_char_idx=0, end_char_idx=964, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.73141545)], metadata={'31ff59b2-1784-4ac9-9ef7-cebf6925ce2f': {'id': '0187', 'region': 'EMEA', 'country': 'UK', 'title': 'Dibaba breaks 5,000m world record', 'description': 'Ethiopia\\'s Tirunesh Dibaba set a new world record in winning the women\\'s 5,000m at the Boston Indoor Games.\\n\\nDibaba won in 14 minutes 32.93 seconds to erase the previous world indoor mark of 14:39.29 set by another Ethiopian, Berhane Adera, in Stuttgart last year. But compatriot Kenenisa Bekele\\'s record hopes were dashed when he miscounted his laps in the men\\'s 3,000m and staged his sprint finish a lap too soon. Ireland\\'s Alistair Cragg won in 7:39.89 as Bekele battled to second in 7:41.42. \"I didn\\'t want to sit back and get out-kicked,\" said Cragg. \"So I kept on the pace. The plan was to go with 500m to go no matter what, but when Bekele made the mistake that was it. The race was mine.\" Sweden\\'s Carolina Kluft, the Olympic heptathlon champion, and Slovenia\\'s Jolanda Ceplak had winning performances, too. Kluft took the long jump at 6.63m, while Ceplak easily won the women\\'s 800m in 2:01.52.\\n', 'theme': 'Sport', 'header_path': '/'}})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine.query(\"what was the womans running event?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab1e6c2-395b-42ab-84b1-23bb16520997",
   "metadata": {},
   "source": [
    "## Search and retrieval based on Filters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9085dd80-600e-443a-b350-a3b78cf8aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '0185', 'region': 'EMEA', 'country': 'UK', 'title': 'Labour plans maternity pay rise', 'description': 'Maternity pay for new mothers is to rise by £1,400 as part of new proposals announced by the Trade and Industry Secretary Patricia Hewitt.\\n\\nIt would mean paid leave would be increased to nine months by 2007, Ms Hewitt told GMTV\\'s Sunday programme. Other plans include letting maternity pay be given to fathers and extending rights to parents of older children. The Tories dismissed the maternity pay plan as \"desperate\", while the Liberal Democrats said it was misdirected.\\n\\nMs Hewitt said: \"We have already doubled the length of maternity pay, it was 13 weeks when we were elected, we have already taken it up to 26 weeks. \"We are going to extend the pay to nine months by 2007 and the aim is to get it right up to the full 12 months by the end of the next Parliament.\" She said new mothers were already entitled to 12 months leave, but that many women could not take it as only six of those months were paid. \"We have made a firm commitment. We will definitely extend the maternity pay, from the six months where it now is to nine months, that\\'s the extra £1,400.\" She said ministers would consult on other proposals that could see fathers being allowed to take some of their partner\\'s maternity pay or leave period, or extending the rights of flexible working to carers or parents of older children. The Shadow Secretary of State for the Family, Theresa May, said: \"These plans were announced by Gordon Brown in his pre-budget review in December and Tony Blair is now recycling it in his desperate bid to win back women voters.\"', 'theme': 'Politics', 'header_path': '/'}\n",
      "**Title**\n",
      "Labour plans maternity pay rise\n",
      "\n",
      "**Description**\n",
      "Maternity pay for new mothers is to rise by £1,400 as part of new proposals announced by the Trade and Industry Secretary Patricia Hewitt.\n",
      "\n",
      "It would mean paid leave would be increased to nine months by 2007, Ms Hewitt told GMTV's Sunday programme. Other plans include letting maternity pay be given to fathers and extending rights to parents of older children. The Tories dismissed the maternity pay plan as \"desperate\", while the Liberal Democrats said it was misdirected.\n",
      "\n",
      "Ms Hewitt said: \"We have already doubled the length of maternity pay, it was 13 weeks when we were elected, we have already taken it up to 26 weeks. \"We are going to extend the pay to nine months by 2007 and the aim is to get it right up to the full 12 months by the end of the next Parliament.\" She said new mothers were already entitled to 12 months leave, but that many women could not take it as only six of those months were paid. \"We have made a firm commitment. We will definitely extend the maternity pay, from the six months where it now is to nine months, that's the extra £1,400.\" She said ministers would consult on other proposals that could see fathers being allowed to take some of their partner's maternity pay or leave period, or extending the rights of flexible working to carers or parents of older children. The Shadow Secretary of State for the Family, Theresa May, said: \"These plans were announced by Gordon Brown in his pre-budget review in December and Tony Blair is now recycling it in his desperate bid to win back women voters.\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"country\", value=\"UK\"),\n",
    "        ]\n",
    ")\n",
    "\n",
    "retriever = bbc_index.as_retriever(\n",
    "    similarity_top_k=1,\n",
    "    filters=filters,\n",
    ")\n",
    "\n",
    "retrieved_nodes = retriever.retrieve(\"maternity pay rise plans\")\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    print(node.node.metadata)\n",
    "    print(node.node.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c852cef-7946-469f-873b-0b836bdd539e",
   "metadata": {},
   "source": [
    "## Hybrid Search & Key Matching Filtering\n",
    "\n",
    "Search the index with hybrid query by specifying the vector store query mode: VectorStoreQueryMode.HYBRID with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b1c3399a-d90d-4352-8bb3-7392d7174155",
   "metadata": {},
   "outputs": [
    {
     "ename": "RequestError",
     "evalue": "RequestError(400, 'parsing_exception', 'unknown query [hybrid]')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRequestError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m      4\u001b[39m filters = MetadataFilters(\n\u001b[32m      5\u001b[39m     filters=[\n\u001b[32m      6\u001b[39m         ExactMatchFilter(\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m     ]\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m retriever = bbc_index.as_retriever(\n\u001b[32m     13\u001b[39m     filters=filters, vector_store_query_mode=VectorStoreQueryMode.HYBRID\n\u001b[32m     14\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m result = \u001b[43mretriever\u001b[49m\u001b[43m.\u001b[49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat are the plans to monitor immigration?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index/core/base/base_retriever.py:246\u001b[39m, in \u001b[36mBaseRetriever.retrieve\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.as_trace(\u001b[33m\"\u001b[39m\u001b[33mquery\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    243\u001b[39m         CBEventType.RETRIEVE,\n\u001b[32m    244\u001b[39m         payload={EventPayload.QUERY_STR: query_bundle.query_str},\n\u001b[32m    245\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m         nodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m         nodes = \u001b[38;5;28mself\u001b[39m._handle_recursive_retrieval(query_bundle, nodes)\n\u001b[32m    248\u001b[39m         retrieve_event.on_end(\n\u001b[32m    249\u001b[39m             payload={EventPayload.NODES: nodes},\n\u001b[32m    250\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index_instrumentation/dispatcher.py:319\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    316\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    322\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:104\u001b[39m, in \u001b[36mVectorIndexRetriever._retrieve\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m query_bundle.embedding \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_bundle.embedding_strs) > \u001b[32m0\u001b[39m:\n\u001b[32m     99\u001b[39m         query_bundle.embedding = (\n\u001b[32m    100\u001b[39m             \u001b[38;5;28mself\u001b[39m._embed_model.get_agg_embedding_from_queries(\n\u001b[32m    101\u001b[39m                 query_bundle.embedding_strs\n\u001b[32m    102\u001b[39m             )\n\u001b[32m    103\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index/core/indices/vector_store/retrievers/retriever.py:181\u001b[39m, in \u001b[36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[39m\u001b[34m(self, query_bundle_with_embeddings)\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_nodes_with_embeddings\u001b[39m(\n\u001b[32m    178\u001b[39m     \u001b[38;5;28mself\u001b[39m, query_bundle_with_embeddings: QueryBundle\n\u001b[32m    179\u001b[39m ) -> List[NodeWithScore]:\n\u001b[32m    180\u001b[39m     query = \u001b[38;5;28mself\u001b[39m._build_vector_store_query(query_bundle_with_embeddings)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_vector_store\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._build_node_list_from_query_result(query_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index/vector_stores/opensearch/base.py:1115\u001b[39m, in \u001b[36mOpensearchVectorStore.query\u001b[39m\u001b[34m(self, query, **kwargs)\u001b[39m\n\u001b[32m   1106\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1107\u001b[39m \u001b[33;03mQuery index for top k most similar nodes.\u001b[39;00m\n\u001b[32m   1108\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1111\u001b[39m \n\u001b[32m   1112\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1113\u001b[39m query_embedding = cast(List[\u001b[38;5;28mfloat\u001b[39m], query.query_embedding)\n\u001b[32m-> \u001b[39m\u001b[32m1115\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1116\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1117\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1118\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimilarity_top_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1121\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/llama_index/vector_stores/opensearch/base.py:868\u001b[39m, in \u001b[36mOpensearchVectorClient.query\u001b[39m\u001b[34m(self, query_mode, query_str, query_embedding, k, filters)\u001b[39m\n\u001b[32m    859\u001b[39m     search_query = \u001b[38;5;28mself\u001b[39m._knn_search_query(\n\u001b[32m    860\u001b[39m         \u001b[38;5;28mself\u001b[39m._embedding_field,\n\u001b[32m    861\u001b[39m         query_embedding,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m         excluded_source_fields=\u001b[38;5;28mself\u001b[39m._excluded_source_fields,\n\u001b[32m    865\u001b[39m     )\n\u001b[32m    866\u001b[39m     params = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m868\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_os_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43msearch_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._to_query_result(res)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/opensearchpy/client/utils.py:176\u001b[39m, in \u001b[36mquery_params.<locals>._wrapper.<locals>._wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    174\u001b[39m             params[p] = _escape(v)\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/opensearchpy/client/__init__.py:2431\u001b[39m, in \u001b[36mOpenSearch.search\u001b[39m\u001b[34m(self, body, index, params, headers)\u001b[39m\n\u001b[32m   2428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mfrom_\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[32m   2429\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mfrom\u001b[39m\u001b[33m\"\u001b[39m] = params.pop(\u001b[33m\"\u001b[39m\u001b[33mfrom_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2432\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2433\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_make_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_search\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/opensearchpy/transport.py:457\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    455\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    456\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    459\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    460\u001b[39m     \u001b[38;5;66;03m# connection didn't fail, confirm its live status\u001b[39;00m\n\u001b[32m    461\u001b[39m     \u001b[38;5;28mself\u001b[39m.connection_pool.mark_live(connection)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/opensearchpy/transport.py:418\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    415\u001b[39m connection = \u001b[38;5;28mself\u001b[39m.get_connection()\n\u001b[32m    417\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m418\u001b[39m     status, headers_response, data = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[32m    429\u001b[39m     headers_response = {\n\u001b[32m    430\u001b[39m         header.lower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response.items()\n\u001b[32m    431\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/opensearchpy/connection/http_urllib3.py:308\u001b[39m, in \u001b[36mUrllib3HttpConnection.perform_request\u001b[39m\u001b[34m(self, method, url, params, body, timeout, ignore, headers)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= response.status < \u001b[32m300\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m response.status \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28mself\u001b[39m.log_request_fail(\n\u001b[32m    306\u001b[39m         method, full_url, url, orig_body, duration, response.status, raw_data\n\u001b[32m    307\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent-type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[38;5;28mself\u001b[39m.log_request_success(\n\u001b[32m    315\u001b[39m     method, full_url, url, orig_body, response.status, raw_data, duration\n\u001b[32m    316\u001b[39m )\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response.status, response.headers, raw_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Projects/LLM_Agents/Llama_Index_Pipelines/LLM-pipelines/venv/lib/python3.11/site-packages/opensearchpy/connection/base.py:315\u001b[39m, in \u001b[36mConnection._raise_error\u001b[39m\u001b[34m(self, status_code, raw_data, content_type)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    313\u001b[39m     logger.warning(\u001b[33m\"\u001b[39m\u001b[33mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, err)\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS.get(status_code, TransportError)(\n\u001b[32m    316\u001b[39m     status_code, error_message, additional_info\n\u001b[32m    317\u001b[39m )\n",
      "\u001b[31mRequestError\u001b[39m: RequestError(400, 'parsing_exception', 'unknown query [hybrid]')"
     ]
    }
   ],
   "source": [
    "from llama_index.core.vector_stores import ExactMatchFilter, MetadataFilters\n",
    "from llama_index.core.vector_stores.types import VectorStoreQueryMode\n",
    "\n",
    "filters = MetadataFilters(\n",
    "    filters=[\n",
    "        ExactMatchFilter(\n",
    "            key=\"term\", value='{\"metadata.theme.keyword\": \"Politics\"}'\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever = bbc_index.as_retriever(\n",
    "    filters=filters, vector_store_query_mode=VectorStoreQueryMode.HYBRID\n",
    ")\n",
    "\n",
    "result = retriever.retrieve(\"what are the plans to monitor immigration?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa800347-1b40-4a8e-b062-c5e62b44e91d",
   "metadata": {},
   "source": [
    "## Query the Postgres Document store database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6129627d-a38c-4f4c-8810-3471593a89b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'id': '0185', 'theme': 'Politics', 'title': 'Labour plans maternity pay rise', 'region': 'EMEA', 'country': 'UK', 'description': 'Maternity pay for new mothers is to rise by £1,400 as part of new proposals announced by the Trade and Industry Secretary Patricia Hewitt.\\n\\nIt would mean paid leave would be increased to nine months by 2007, Ms Hewitt told GMTV\\'s Sunday programme. Other plans include letting maternity pay be given to fathers and extending rights to parents of older children. The Tories dismissed the maternity pay plan as \"desperate\", while the Liberal Democrats said it was misdirected.\\n\\nMs Hewitt said: \"We have already doubled the length of maternity pay, it was 13 weeks when we were elected, we have already taken it up to 26 weeks. \"We are going to extend the pay to nine months by 2007 and the aim is to get it right up to the full 12 months by the end of the next Parliament.\" She said new mothers were already entitled to 12 months leave, but that many women could not take it as only six of those months were paid. \"We have made a firm commitment. We will definitely extend the maternity pay, from the six months where it now is to nine months, that\\'s the extra £1,400.\" She said ministers would consult on other proposals that could see fathers being allowed to take some of their partner\\'s maternity pay or leave period, or extending the rights of flexible working to carers or parents of older children. The Shadow Secretary of State for the Family, Theresa May, said: \"These plans were announced by Gordon Brown in his pre-budget review in December and Tony Blair is now recycling it in his desperate bid to win back women voters.\"'},)\n",
      "({'id': '0186', 'theme': 'Politics', 'title': \"UK 'needs true immigration data'\", 'region': 'EMEA', 'country': 'UK', 'description': 'A former Home Office minister has called for an independent body to be set up to monitor UK immigration.\\n\\nBarbara Roche said an organisation should monitor and publish figures and be independent of government. She said this would counter \"so-called independent\" groups like Migration Watch, which she described as an anti-immigration body posing as independent. Migration Watch says it is not against all immigration and the government already publishes accurate figures. Sir Andrew Green, chairman of the organisation, says there is no need for an independent body because Office of National Statistics data are accurate. He says he opposes large-scale immigration \"both on the grounds of overcrowding and culture\".'},)\n",
      "({'id': '0187', 'theme': 'Sport', 'title': 'Dibaba breaks 5,000m world record', 'region': 'EMEA', 'country': 'UK', 'description': 'Ethiopia\\'s Tirunesh Dibaba set a new world record in winning the women\\'s 5,000m at the Boston Indoor Games.\\n\\nDibaba won in 14 minutes 32.93 seconds to erase the previous world indoor mark of 14:39.29 set by another Ethiopian, Berhane Adera, in Stuttgart last year. But compatriot Kenenisa Bekele\\'s record hopes were dashed when he miscounted his laps in the men\\'s 3,000m and staged his sprint finish a lap too soon. Ireland\\'s Alistair Cragg won in 7:39.89 as Bekele battled to second in 7:41.42. \"I didn\\'t want to sit back and get out-kicked,\" said Cragg. \"So I kept on the pace. The plan was to go with 500m to go no matter what, but when Bekele made the mistake that was it. The race was mine.\" Sweden\\'s Carolina Kluft, the Olympic heptathlon champion, and Slovenia\\'s Jolanda Ceplak had winning performances, too. Kluft took the long jump at 6.63m, while Ceplak easily won the women\\'s 800m in 2:01.52.\\n'},)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Set up your connection (adjust credentials accordingly)\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    dbname=\"vectortutorial\",\n",
    "    user=\"postgres\",\n",
    "    password=\"password\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Correct SQL query using parameter placeholders\n",
    "sql = \"\"\"\n",
    "SELECT DISTINCT value->'__data__'->'metadata'\n",
    "FROM public.data_experiment_bbc_ds \n",
    "WHERE value->'__data__'->'metadata'->>'country' = %s;\n",
    "\"\"\"\n",
    "\n",
    "# Execute with 'UK' as a parameter\n",
    "cur.execute(sql, ('UK',))\n",
    "\n",
    "# Fetch results\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Process results\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c0cc36-48b1-470a-9734-ab01149913de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcp_venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
